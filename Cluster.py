#! /usr/bin/python
# Author: Dave Curran
# Date  : October 2011
# # # # # # # # # # # #
""" A class that performs RMSD clustering on protein structure files.

    This software was created in order to better parse the thousands of results
generated by simulating the docking of two proteins. All of the fundamental math
was from 'Molecular Distance Measures' by Lydia Kavraki, from cnx.org. All of this
was actually understood and verified by Jamie Fegan. This module uses quaternions
to align protein structures, which while complicated, have closed-form unique
solutions and are fairly resistant to accumulation of floating-point errors.

Note: This module assumes at all times that all files are already sequence-aligned,
such that atom 1 from pdbA is the same as atom 1 from pdbB. It also assumes that
any files with the same basename are the same. So if filenameA exists in 2 different
locations, and describes 2 different files, clearCache() must be called before using
the other, or it will not actually be read in.

Usage : Instanciate the Clusterer() with no arguments. This class defines the
following methods:

    -- calcRmsd(pathA, pathB) -- where the paths point to 2 pdb files, will return
a float, the least root mean squared deviation between the structures.

    -- cluster([threshold, path, targets]) -- (all arguments are optional),
with arguments threshold: a float (the radius in Angstrom to define a cluster),
path: a path to a folder containing pdb files to be clustered, and/or targets: a list
of filenames from 'path' (only these files will be clustered). Calling cluster
without a path will cause it to run on the same directory as last time without
recalculating pairwise RMSD, but with the new cluster radius. This returns a list
of lists, each containing names of the structures in that cluster. The first name
per list is the center of that cluster.

    -- align(alignThis, toThis, newFilename) -- will align the structure 'alignThis'
to the structure 'toThis', and save it as a pdb called 'newFilename'.

    -- clearCache() -- will wipe any saved data from the clusterer. Typically used
when clustering a new directory, so that different structures with the same name will
not be confused by the program.
"""
import os, gc, itertools
import numpy
from math import sqrt


class Clusterer:
    def __init__(self):
        self.currentDirectory = None
        self.rmsds = {}
        self.decoys = {} # The names and their neighbours
        self.__centeredCoords = {}
        # # #  Functions for progress bars  # # #
        self._readProgressStep = 10
        self._readProgressFxn = None
        self._cmpProgressStep = 100
        self._cmpProgressFxn = None

    def calcRmsd(self, filepathA, filepathB):
        """Pass in two filepaths for 2 pdbs, and returns the RMSD between the structures
        as a float. Each structure will be cached, so if many calls are made with the
        same structures, operates much faster. Because only the filename is cached, not the
        full file path, 2 different structures with the same filename will be treated as
        the same file. Call clearCache() between calls to prevent this."""
        for path in (filepathA, filepathB):
            if not os.path.isfile(path) or not path.endswith('.pdb'):
                return False
        fileA, fileB = os.path.basename(filepathA), os.path.basename(filepathB)
        if fileA == fileB: return False
        if fileA not in self.__centeredCoords: self.__readInPdb(filepathA)
        if fileB not in self.__centeredCoords: self.__readInPdb(filepathB)
        rmsd = self.__calcRmsd(fileA, fileB)
        return rmsd

    def cluster(self, threshold=4.5, path=None, targets=None):
        # progStep=0, progFxn=None):
        """Pass it the path to some folder of pdbs, and an optional min radius for
        defining a cluster (in Angstroms). Returns a list of lists, each representing
        a cluster of structures, where the first name is the center of the cluster.
        The optional 'targets' is a list of filenames from the 'path' directory, and if
        given only those files will be considered in the clustering. The other args are
        for a progress bar; progFxn will be called with no arguments after the number of
        calculations defined by 'progStep'.
        Note: as this uses pairwise RMSD it can be slow; about 7 ms per compare. If this
        is called on the same directory twice, the distances will only be calculated
        once."""
        if path == None: path = self.currentDirectory
        if not os.path.isdir(path): return False
        else: path = os.path.abspath(path)
        if not targets:
            targets = [f for f in os.listdir(path) if f.endswith('.pdb')]
        targets = filter(lambda name: os.path.isfile(os.path.join(path, name)), targets)
        if len(targets) < 2: return False
        #if type(progStep) != int: return False
        if self.currentDirectory != path:
            self.clearCache()
            self.currentDirectory = path
        self.decoys = dict((name, []) for name in targets)
        #self.__estimateRmsds(threshold, path, targets, progStep, progFxn)
        self.__estimateRmsds(threshold, path, targets)
        clustered = self.__findClusters(threshold)
        return clustered

    def align(self, alignThis, toThis, newFilepath):
        """Reads in coords from 'alignThis', aligns it to 'toThis', and saves
        the new structure to newFilepath. Only ATOM and HETATM lines will be
        rotated in the new structure, and the coords are not saved in the cache."""
        for path in (alignThis, toThis):
            if not os.path.isfile(path) or not path.endswith('.pdb'):
                return False
        if not newFilepath.endswith('.pdb'): newFilepath += '.pdb'
        
        tarCoords, tarCent = self.__parseCoordsCentroid(alignThis, False)
        coordsB, centB = self.__parseCoordsCentroid(toThis, False)
        tarCoords -= tarCent; coordsB -= centB
        alignedCoords = self.__align(tarCoords, coordsB) + centB
        
        buff = []
        old = open(alignThis, 'rb')
        coordsIter = ((x,y,z) for x,y,z in alignedCoords)
        for line in old:
            if line.startswith('ATOM') or line.startswith('HETATM'):
                buff.append(''.join([line[:30], '%8.3f%8.3f%8.3f ' % coordsIter.next(), line[55:]]))
            else: buff.append(line)
        old.close()
        f = open(newFilepath, 'wb')
        f.write(''.join(buff)); f.close()

    def clearCache(self):
        """Wipes all saved data."""
        del self.currentDirectory
        del self.rmsds
        del self.decoys
        del self.__centeredCoords
        self.currentDirectory = None
        self.rmsds = {}
        self.decoys = {}
        self.__centeredCoords = {}

    # # # # # # # # # #  RMSD Private Methods  # # # # # # # # # #
    def __calcRmsd(self, fileA, fileB):
        protA, protB = self.__centeredCoords[fileA], self.__centeredCoords[fileB]
        protA = self.__align(protA, protB)
        rmsd = sqrt(numpy.sum(numpy.square(protB-protA)) / len(protB))
        return rmsd
    def __align(self, coordsA, coordsB):
        """Aligns name fileA to name fileB, returning the set of coords for the new
        rotatedA. Only works if coordsA and B are both centered on 0."""
        rotQuat = self.__optimalRotation(coordsA, coordsB) # 90% of the processing time
        rotatedA = self.__quaternionRotate(rotQuat, coordsA)
        return rotatedA
    def __optimalRotation(self, a, b):
        """This returns a numpy matrix of a quaternion indicating the rotation on A
        that brings it closest to B. A note: when creating the N matrix, it is first
        generated as a flat list 16 elements long. It is made into a 4x4 matrix after
        the final sum is found."""
        N = reduce(self.__addSeqs, self.__nGen(a.tolist(),b.tolist()))
        eigVals, eigVecs = numpy.linalg.eig(numpy.array(N).reshape(4,4))
        i = list(eigVals).index(max(eigVals))
        return eigVecs[:,i]
    def __quaternionRotate(self, q, coords):
        a, b, c, d = q
        m = numpy.array([[a*a+b*b-c*c-d*d, 2*a*d+2*b*c, 2*b*d-2*a*c],
                         [2*b*c-2*a*d, a*a-b*b+c*c-d*d, 2*a*b+2*c*d],
                         [2*a*c+2*b*d, 2*c*d-2*a*b, a*a-b*b-c*c+d*d]])
        return numpy.dot(coords, m)
    def __parseCoordsCentroid(self, filepath, onlyCA=True):
        #f = open(filepath, 'rb')
        if onlyCA:
            """c = []
            for line in f2:
                if line.startswith('ATOM') and line[13:15] == 'CA':
                    c.append(( float(line[30:38]),float(line[38:46]),float(line[46:55]) ))
            c2 = numpy.array(c)"""

            coords = numpy.array( [(float(line[30:38]),float(line[38:46]),float(line[46:55]))
                                   for line in open(filepath, 'rb') if line.startswith('ATOM')
                                   and line[13:15] == 'CA'] )
            
        else:
            coords = numpy.array( [[float(line[30:38]),float(line[38:46]),float(line[46:55])]
                                   for line in open(filepath, 'rb') if line.startswith('ATOM')
                                   or line.startswith('HETATM')] )
       
        #    coords = numpy.array( [[float(n) for n in line[31:55].split()] for line in f
        #                           if line.startswith('ATOM') and line[13:15] == 'CA'] )
        #else:
        #    coords = numpy.array( [[float(n) for n in line[31:55].split()] for line in f
        #                           if line.startswith('ATOM') or line.startswith('HETATM')] )
        #f.close()
        centroid = numpy.mean(coords, 0)
        return coords, centroid
    def __readInPdb(self, filepath):
        name = os.path.basename(filepath)
        coords, centroid = self.__parseCoordsCentroid(filepath)
        self.__centeredCoords[name] = coords - centroid
    def __addSeqs(self, seq1, seq2):
        return [ele1 + ele2 for ele1, ele2 in zip(seq1,seq2)]
    def __nGen(self, coordsA, coordsB):
        for a, b in zip(coordsA, coordsB):
            axbx=a[0]*b[0];axby=a[0]*b[1];axbz=a[0]*b[2]
            aybx=a[1]*b[0];ayby=a[1]*b[1];aybz=a[1]*b[2]
            azbx=a[2]*b[0];azby=a[2]*b[1];azbz=a[2]*b[2]
            yield [axbx+ayby+azbz, aybz-azby, azbx-axbz, axby-aybx,
                   aybz-azby, axbx-azbz-ayby, axby+aybx, axbz+azbx,
                   azbx-axbz, aybx+axby, ayby-azbz-axbx, aybz+azby,
                   axby-aybx, azbx+axbz, azby+aybz, azbz-ayby-axbx]
    # # # # # # # # # #  Clustering Private Methods  # # # # # # # # # #
    def __estimateRmsds(self, threshold, dirPath, targets):
        # , progStep, readProgFxn):
        """Finds RMSD between all files in the list 'targets'. Values are calculated
        between the first file and all others, but other pairs are only calculated if
        the RMSD of AB - RMSD of AC is less than the threshold. None is saved as the RMSD
        if the true value will be greater than the threshold."""
        def defaultReadFxn():
            total, done = len(targets), 0
            while True:
                done += self._readProgressStep
                print '%i of %i files loaded.' % (done, total)
                yield done
        def defaultCmpFxn():
            total, done = len(targets) * (len(targets)-1) / 2, 0
            while True:
                done += self._cmpProgressStep
                print '%i of %i compares done.' % (done, total)
                yield done            
        gc.disable()
        rmsds = self.rmsds
        rdFxn = self._readProgressFxn
        cmpFxn = self._cmpProgressFxn
        if not callable(rdFxn): rdFxn = defaultReadFxn().next
        if not callable(cmpFxn): cmpFxn = defaultCmpFxn().next
        
        fileA = targets[0]
        pathA = os.path.join(dirPath, fileA)
        if not rmsds:
            self.rmsds = rmsds = dict.fromkeys(itertools.permutations(targets, 2))

        # Below is the slow part about reading in the files. It appears 0.5 sec per file
        # on a remote machine is about normal, but sometimes that machine will cache them
        # so they are opened in 0.05 sec instead. 
        for i, name in enumerate(targets):
            if name not in self.__centeredCoords:
                self.__readInPdb(os.path.join(dirPath,name))
            if rdFxn and i % self._readProgressStep == 0:
                rdFxn() # add default printing fxn

        firstDists = dict( ( fileB, rmsds.get((fileA,fileB)) or
                             self.__calcRmsd(fileA,fileB) )
                           for fileB in targets[1:] )

        i = len(targets)-1
        while i >= self._cmpProgressStep:
            if cmpFxn: cmpFxn()
            i -= self._cmpProgressStep
        for fileB, fileC in itertools.combinations(targets[1:],2):
            if not rmsds.setdefault((fileB, fileC)) and not rmsds.setdefault((fileC, fileB)) and abs(firstDists[fileB] - firstDists[fileC]) <= threshold:
                distBC = self.calcRmsd(os.path.join(dirPath, fileB),
                                       os.path.join(dirPath, fileC))
                rmsds[fileB,fileC] = distBC
                rmsds[fileC,fileB] = distBC
            i += 1
            if i >= self._cmpProgressStep:
                i = 0
                if cmpFxn: cmpFxn()
        for fileB, dist in firstDists.items():
            rmsds[fileA,fileB] = dist
            rmsds[fileB,fileA] = dist
        gc.enable()
    def __pairwiseRmsdOLD(self, dirPath, folder, progStep, progFxn):
        """Depreciated in favour of the estimation above."""
        self.__centeredCoords = {}
        if not callable(progFxn): progFxn = None
        decoys, i = {}, 0
        for fileA, fileB in itertools.combinations(folder,2):
            pathA = os.path.join(dirPath, fileA)
            pathB = os.path.join(dirPath, fileB)
            rmsd = self.calcRmsd(pathA, pathB)
            decoys.setdefault(fileA, {})[fileB] = rmsd
            decoys.setdefault(fileB, {})[fileA] = rmsd
            i += 1
            if i == progStep:
                i = 0
                if progFxn: progFxn()
        return decoys
    
    def __findClusters(self, clusterThreshold):
        # This optimized? Am i traversing the list n^2 times?
        self.__updateDecoyNeighbors(clusterThreshold)
        clustered = []
        remaining = sorted(self.decoys, key=lambda d: -len(self.decoys[d]))
        for name in remaining:
            if not name: continue
            neighbors = filter(lambda n: n in remaining, self.decoys[name])
            if len(neighbors) == 0:
                clustered.append(name)
                continue
            clustered.append([name]+neighbors)
            for neighbor in neighbors:
                if neighbor in remaining: remaining[remaining.index(neighbor)] = False
        return clustered
    def __updateDecoyNeighbors(self, threshold):
        for fileA, fileB in itertools.combinations(self.decoys, 2):
            dist = self.rmsds[fileA,fileB]
            if dist != None and dist < threshold:
                self.decoys[fileA].append(fileB)
                self.decoys[fileB].append(fileA)

